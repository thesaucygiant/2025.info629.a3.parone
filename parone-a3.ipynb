{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafeed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Customer Churn Prediction - Supervised Learning Demo\n",
    "Binary Classification using Random Forest\n",
    "\n",
    "Dataset: Telco Customer Churn from Kaggle\n",
    "https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
    "\n",
    "Package Requirements:\n",
    "\n",
    "pandas 2.3.2\n",
    "numpy 2.2.6\n",
    "scikit-learn 1.7.2\n",
    "matplotlib 3.10.7\n",
    "seaborn 0.13.2\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score, \n",
    "    recall_score, f1_score, roc_auc_score, classification_report\n",
    ")\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load and prepare data\n",
    "def load_data():\n",
    "    #Load the Telco Customer Churn dataset\n",
    "    #Download from: https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
    "    \n",
    "    # For demo purposes, using publicly available dataset\n",
    "    #url = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
    "    #WA_Fn-UseC_-Telco-Customer-Churn\n",
    "    #df = pd.read_csv(url)\n",
    "    df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    print(f\"\\nChurn distribution:\\n{df['Churn'].value_counts()}\")\n",
    "    print(\"=\"*60)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    #Clean and prepare data for modeling\n",
    "    #Make a copy to avoid warnings\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert TotalCharges to numeric and fill missing values\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "    df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "    \n",
    "    # Drop customerID\n",
    "    df = df.drop('customerID', axis=1)\n",
    "    \n",
    "    # Convert target variable\n",
    "    df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le = LabelEncoder()\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Data preprocessed. Shape: {df.shape}\")\n",
    "    print(\"=\"*60)\n",
    "    return df\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"Train Random Forest Classifier\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Training Random Forest Classifier...\")\n",
    "    \n",
    "    # Initialize model with balanced class weights\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training completed!\")\n",
    "    print(\"=\"*60)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"model evaluation\"\"\"\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nAccuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "    print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "    print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "    print(f\"ROC-AUC:   {roc_auc:.4f} ({roc_auc*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\n{'CONFUSION MATRIX':^40}\")\n",
    "    print(f\"{'':20} {'Predicted':^20}\")\n",
    "    print(f\"{'':20} {'No Churn':^10} {'Churn':^10}\")\n",
    "    print(f\"{'Actual No Churn':20} {tn:^10} {fp:^10}\")\n",
    "    print(f\"{'Actual Churn':20} {fn:^10} {tp:^10}\")\n",
    "    \n",
    "    print(f\"\\nTrue Negatives (TN):  {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"True Positives (TP):  {tp}\")\n",
    "    \n",
    "    print(\"\\n\" + classification_report(y_test, y_pred, \n",
    "                                       target_names=['No Churn', 'Churn']))\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['No Churn', 'Churn'],\n",
    "                yticklabels=['No Churn', 'Churn'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    print(\"\\nConfusion matrix saved as 'confusion_matrix.png'\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'confusion_matrix': {'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp}\n",
    "    }\n",
    "\n",
    "def feature_importance(model, feature_names):\n",
    "    \"\"\"Display feature importance\"\"\"\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:10]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TOP 10 MOST IMPORTANT FEATURES\")\n",
    "    print(\"=\"*60)\n",
    "    for i, idx in enumerate(indices, 1):\n",
    "        print(f\"{i:2d}. {feature_names[idx]:30s} {importances[idx]:.4f}\")\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(10), importances[indices])\n",
    "    plt.xticks(range(10), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "    plt.title('Top 10 Feature Importances')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    print(\"\\nFeature importance plot saved as 'feature_importance.png'\")\n",
    "\n",
    "def test_cases(model, feature_names):\n",
    "    \"\"\"Test with specific examples\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST PREDICTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test Case 1\n",
    "    testcase1 = {\n",
    "        'gender': 1, 'SeniorCitizen': 0, 'Partner': 0, 'Dependents': 0,\n",
    "        'tenure': 3, 'PhoneService': 1, 'MultipleLines': 0, \n",
    "        'InternetService': 1, 'OnlineSecurity': 0, 'OnlineBackup': 0,\n",
    "        'DeviceProtection': 0, 'TechSupport': 0, 'StreamingTV': 0,\n",
    "        'StreamingMovies': 0, 'Contract': 0, 'PaperlessBilling': 1,\n",
    "        'PaymentMethod': 2, 'MonthlyCharges': 95.0, 'TotalCharges': 285.0\n",
    "    }\n",
    "    \n",
    "    # Test Case 2\n",
    "    testcase2 = {\n",
    "        'gender': 0, 'SeniorCitizen': 1, 'Partner': 1, 'Dependents': 1,\n",
    "        'tenure': 60, 'PhoneService': 1, 'MultipleLines': 1,\n",
    "        'InternetService': 0, 'OnlineSecurity': 2, 'OnlineBackup': 1,\n",
    "        'DeviceProtection': 1, 'TechSupport': 1, 'StreamingTV': 1,\n",
    "        'StreamingMovies': 1, 'Contract': 2, 'PaperlessBilling': 0,\n",
    "        'PaymentMethod': 0, 'MonthlyCharges': 55.0, 'TotalCharges': 3300.0\n",
    "    }\n",
    "    \n",
    "    # Test Case 3\n",
    "    testcase3 = {\n",
    "        'gender': 1, 'SeniorCitizen': 0, 'Partner': 1, 'Dependents': 0,\n",
    "        'tenure': 18, 'PhoneService': 1, 'MultipleLines': 1,\n",
    "        'InternetService': 1, 'OnlineSecurity': 0, 'OnlineBackup': 1,\n",
    "        'DeviceProtection': 1, 'TechSupport': 1, 'StreamingTV': 0,\n",
    "        'StreamingMovies': 1, 'Contract': 1, 'PaperlessBilling': 1,\n",
    "        'PaymentMethod': 1, 'MonthlyCharges': 70.0, 'TotalCharges': 1260.0\n",
    "    }\n",
    "    \n",
    "    # Test Case 4\n",
    "    testcase4 = {\n",
    "        'gender': 1, 'SeniorCitizen': 0, 'Partner': 1, 'Dependents': 8,\n",
    "        'tenure': 18, 'PhoneService': 0, 'MultipleLines': 0,\n",
    "        'InternetService': 1, 'OnlineSecurity': 0, 'OnlineBackup': 0,\n",
    "        'DeviceProtection': 0, 'TechSupport': 0, 'StreamingTV': 1,\n",
    "        'StreamingMovies': 1, 'Contract': 1, 'PaperlessBilling': 1,\n",
    "        'PaymentMethod': 1, 'MonthlyCharges': 200.0, 'TotalCharges': 1260.0\n",
    "    }\n",
    "    \n",
    "    testcases = [\n",
    "        (\"Test Case 1: New customer, expensive, month-to-month, no support\", testcase1),\n",
    "        (\"Test Case 2: Long tenure, 2-year contract, full services\", testcase2),\n",
    "        (\"Test Case 3: Moderate tenure, 1-year contract, mixed services\", testcase3),\n",
    "        (\"Test Case 4: Moderate tenure, 8 dependents, 1-year contract, mixed services\", testcase4)\n",
    "    ]\n",
    "    \n",
    "    for desc, testcase in testcases:\n",
    "        X_testcase = pd.DataFrame([testcase])[feature_names]\n",
    "        pred = model.predict(X_testcase)[0]\n",
    "        proba = model.predict_proba(X_testcase)[0]\n",
    "        \n",
    "        print(f\"\\n{desc}\")\n",
    "        print(f\"  Prediction: {'CHURN' if pred == 1 else 'NO CHURN'}\")\n",
    "        print(f\"  Probability: {proba[1]*100:.1f}% chance of churn\")\n",
    "        \n",
    "def visualize_single_tree(model, feature_names, tree_index=0):\n",
    "    #Visualize a single decision tree from the Random Forest model\n",
    "    \n",
    "    # Get a single tree from the forest\n",
    "    single_tree = model.estimators_[tree_index]\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(single_tree, \n",
    "              feature_names=feature_names,\n",
    "              class_names=['No Churn', 'Churn'],\n",
    "              filled=True,\n",
    "              rounded=True,\n",
    "              fontsize=10)\n",
    "    plt.title(f'Decision Tree #{tree_index} from Random Forest')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'decision_tree_{tree_index}.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nDecision tree #{tree_index} saved as 'decision_tree_{tree_index}.png'\")\n",
    "    \n",
    "    # Also export text representation\n",
    "    tree_rules = export_text(single_tree, feature_names=feature_names)\n",
    "    with open(f'tree_rules_{tree_index}.txt', 'w') as f:\n",
    "        f.write(tree_rules)\n",
    "    print(f\"Tree rules saved as 'tree_rules_{tree_index}.txt'\")\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    \"\"\"Starting the analysis\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"Course: INFO-629-686 - FA 25-26\")\n",
    "    print(\"Assignment 3: SUPERVISED LEARNING DEMO - CUSTOMER CHURN PREDICTION\")\n",
    "    print(\"Student: Anthony Parone\")\n",
    "    print(\"Date: November 2025\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load the data into a dataframe\n",
    "    df = load_data()\n",
    "    \n",
    "    #2 Preprocess - this cleans up the data for the model training\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    #3 Split features and target\n",
    "    #remove the column churn and leave all the features for X\n",
    "    X = df.drop('Churn', axis=1)\n",
    "    #only the churn values get assigned to Y\n",
    "    y = df['Churn']\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Class distribution:\")\n",
    "    print(f\"  No Churn: {(y==0).sum()} ({(y==0).sum()/len(y)*100:.1f}%)\")\n",
    "    print(f\"  Churn:    {(y==1).sum()} ({(y==1).sum()/len(y)*100:.1f}%)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Train-test split - The Split Creates 4 Sets:\n",
    "    #`X_train`** - Features for training (70% of data)\n",
    "    #**`X_test`** - Features for testing (30% of data)\n",
    "    # **`y_train`** - Target labels for training (70% of data)\n",
    "    #**`y_test`** - Target labels for testing (30% of data)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    '''\n",
    "train_test_split: A function from sklearn.model_selection that splits your dataset into training and testing subsets.\n",
    "X: Your feature matrix (all input variables except the target).\n",
    "y: Your target variable (in this case, Churn).\n",
    "test_size=0.3: 30% of the data will be used for testing, and 70% for training.\n",
    "random_state=42: Sets a fixed seed for reproducibility. Using the same seed ensures you get the same split every time you run the code.\n",
    "stratify=y: Ensures that the proportion of classes (Churn vs. No Churn) is preserved in both training and testing sets. This is important for imbalanced datasets.\n",
    "'''\n",
    "    print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set:  {X_test.shape[0]} samples\")\n",
    "    \n",
    "    # Train model\n",
    "    model = train_model(X_train, y_train)\n",
    "    #vizualize one tree\n",
    "    visualize_single_tree(model, X.columns.tolist(), tree_index=0)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance(model, X.columns.tolist())\n",
    "    \n",
    "    # Test examples\n",
    "    test_cases(model, X.columns.tolist())\n",
    "    \n",
    "    #print(\"\\n\" + \"=\"*60)\n",
    "    #print(\"DEMO COMPLETED SUCCESSFULLY\")\n",
    "    #print(\"=\"*60)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
